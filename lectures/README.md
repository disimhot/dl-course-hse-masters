## Лекция 1. Методы оптимизации

Дополнительные материалы

Статьи:
- [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)
- [Decoupled Weight Decay Regularization](https://arxiv.org/abs/1711.05101)
- [L-BFGS aka quasi-Newton in PyTorch](https://en.wikipedia.org/wiki/Limited-memory_BFGS)

Документация:
- [PyTorch optim](https://pytorch.org/docs/stable/optim.html)
- [LBFGS](https://pytorch.org/docs/stable/generated/torch.optim.LBFGS.html)


Отдельная благодарность [Дмитрию](https://github.com/KuBaN658) за оформление конспекта 1 лекции более понятным почерком (Lec1_pretty).
